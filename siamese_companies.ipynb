{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_companies.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f4gAqFlXRkLS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OngDwkW7jQKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install --upgrade git+https://github.com/flairNLP/flair.git\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-a3FKSPp70q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Alternate way to connect google drive to colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GauvlwcfqEmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Character embeddings saved dataset\n",
        "# %time !cp \"/content/drive/My Drive/Colab Notebooks/train.npz\" \"/content/train.npz\" \n",
        "# %time !cp \"/content/drive/My Drive/Colab Notebooks/val.npz\" \"/content/val.npz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubzT_Lk4G0mJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "# ! unzip crawl-300d-2M-subword.zip\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V63ubllE1ziH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json /root/.kaggle/\n",
        "! chmod 600 /root/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d peopledatalabssf/free-7-million-company-dataset\n",
        "! unzip free-7-million-company-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDZwtQa020iB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "import string\n",
        "import operator\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stopset = list(string.punctuation)\n",
        "stopset.remove(\"&\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WT_ijS4rrpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "dbe385d1-3b15-4dae-c29a-bea7edb06dff"
      },
      "source": [
        "df = pd.read_csv('companies_sorted.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>domain</th>\n",
              "      <th>year founded</th>\n",
              "      <th>industry</th>\n",
              "      <th>size range</th>\n",
              "      <th>locality</th>\n",
              "      <th>country</th>\n",
              "      <th>linkedin url</th>\n",
              "      <th>current employee estimate</th>\n",
              "      <th>total employee estimate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5872184</td>\n",
              "      <td>ibm</td>\n",
              "      <td>ibm.com</td>\n",
              "      <td>1911.0</td>\n",
              "      <td>information technology and services</td>\n",
              "      <td>10001+</td>\n",
              "      <td>new york, new york, united states</td>\n",
              "      <td>united states</td>\n",
              "      <td>linkedin.com/company/ibm</td>\n",
              "      <td>274047</td>\n",
              "      <td>716906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4425416</td>\n",
              "      <td>tata consultancy services</td>\n",
              "      <td>tcs.com</td>\n",
              "      <td>1968.0</td>\n",
              "      <td>information technology and services</td>\n",
              "      <td>10001+</td>\n",
              "      <td>bombay, maharashtra, india</td>\n",
              "      <td>india</td>\n",
              "      <td>linkedin.com/company/tata-consultancy-services</td>\n",
              "      <td>190771</td>\n",
              "      <td>341369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21074</td>\n",
              "      <td>accenture</td>\n",
              "      <td>accenture.com</td>\n",
              "      <td>1989.0</td>\n",
              "      <td>information technology and services</td>\n",
              "      <td>10001+</td>\n",
              "      <td>dublin, dublin, ireland</td>\n",
              "      <td>ireland</td>\n",
              "      <td>linkedin.com/company/accenture</td>\n",
              "      <td>190689</td>\n",
              "      <td>455768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2309813</td>\n",
              "      <td>us army</td>\n",
              "      <td>goarmy.com</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>military</td>\n",
              "      <td>10001+</td>\n",
              "      <td>alexandria, virginia, united states</td>\n",
              "      <td>united states</td>\n",
              "      <td>linkedin.com/company/us-army</td>\n",
              "      <td>162163</td>\n",
              "      <td>445958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1558607</td>\n",
              "      <td>ey</td>\n",
              "      <td>ey.com</td>\n",
              "      <td>1989.0</td>\n",
              "      <td>accounting</td>\n",
              "      <td>10001+</td>\n",
              "      <td>london, greater london, united kingdom</td>\n",
              "      <td>united kingdom</td>\n",
              "      <td>linkedin.com/company/ernstandyoung</td>\n",
              "      <td>158363</td>\n",
              "      <td>428960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... total employee estimate\n",
              "0     5872184  ...                  716906\n",
              "1     4425416  ...                  341369\n",
              "2       21074  ...                  455768\n",
              "3     2309813  ...                  445958\n",
              "4     1558607  ...                  428960\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8as4qKNrrs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "fae81a0d-ac4d-4680-a061-982208f356d3"
      },
      "source": [
        "print (df.shape, df.columns, df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7173426 entries, 0 to 7173425\n",
            "Data columns (total 11 columns):\n",
            " #   Column                     Dtype  \n",
            "---  ------                     -----  \n",
            " 0   Unnamed: 0                 int64  \n",
            " 1   name                       object \n",
            " 2   domain                     object \n",
            " 3   year founded               float64\n",
            " 4   industry                   object \n",
            " 5   size range                 object \n",
            " 6   locality                   object \n",
            " 7   country                    object \n",
            " 8   linkedin url               object \n",
            " 9   current employee estimate  int64  \n",
            " 10  total employee estimate    int64  \n",
            "dtypes: float64(1), int64(3), object(7)\n",
            "memory usage: 602.0+ MB\n",
            "(7173426, 11) Index(['Unnamed: 0', 'name', 'domain', 'year founded', 'industry',\n",
            "       'size range', 'locality', 'country', 'linkedin url',\n",
            "       'current employee estimate', 'total employee estimate'],\n",
            "      dtype='object') None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGU7hR8U2g9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq = Counter()\n",
        "df[\"name\"].dropna(inplace=True)\n",
        "unique_companies = df[\"name\"].unique()\n",
        "\n",
        "for name in tqdm(unique_companies):\n",
        "    freq.update(str(name).split(\" \"))\n",
        "\n",
        "print(freq.most_common(30))\n",
        "print (len(unique_companies))\n",
        "key_words = [word for (word,_) in freq.most_common(30)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BF2GMue27X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from flair.data import Sentence\n",
        "# from flair.embeddings import FastTextEmbeddings, TransformerWordEmbeddings, FlairEmbeddings, WordEmbeddings, StackedEmbeddings, BytePairEmbeddings\n",
        "\n",
        "# # init glove embedding\n",
        "# glove_embedding = WordEmbeddings('glove')\n",
        "\n",
        "# # init fasttext embedding\n",
        "# fast_embedding = FastTextEmbeddings('crawl-300d-2M-subword.bin')\n",
        "\n",
        "# # init Flair embeddings\n",
        "# flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
        "# flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
        "\n",
        "# # init multilingual BERT\n",
        "# bert_embedding = TransformerWordEmbeddings('bert-base-multilingual-cased')\n",
        "\n",
        "# # init embedding\n",
        "# stack_embedding = StackedEmbeddings(\n",
        "#     [\n",
        "#         # standard FastText word embeddings for English\n",
        "#         WordEmbeddings('en'),\n",
        "#         # Byte pair embeddings for English\n",
        "#         BytePairEmbeddings('en'),\n",
        "#     ]\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohkXwgVz27du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def clean(word):\n",
        "#     word = word.lower()\n",
        "#     word = re.sub(\"[^A-Za-z0-9&]+\", \" \", word)\n",
        "#     w_t = \" \".join([i for i in word_tokenize(word) if i not in stopset])\n",
        "#     w_t = unidecode(w_t)\n",
        "#     return w_t\n",
        "\n",
        "# def load_embeddings(embedding):\n",
        "#     embed_dict = dict()\n",
        "#     for i in tqdm(range(10000)):\n",
        "#         token_emb = []\n",
        "#         c = clean(unique_companies[i])\n",
        "#         sentence = Sentence(c)\n",
        "#         glove_embedding.embed(sentence)\n",
        "#         for token in sentence:\n",
        "#             token_emb.append(token.embedding.numpy())\n",
        "#         embed_dict[unique_companies[i]] = np.array(token_emb).mean(axis=0).tolist()\n",
        "#     return embed_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFBhaJdI27kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed = load_embeddings(glove_embedding)\n",
        "# print (len(embed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCGiR7XfD15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_similarity(token, top_n=5):\n",
        "#     res = dict()\n",
        "#     c = clean(token)\n",
        "#     sentence = Sentence(c)\n",
        "#     glove_embedding.embed(sentence)\n",
        "#     token_emb = []\n",
        "#     for token in sentence:\n",
        "#         token_emb.append(token.embedding.numpy())\n",
        "#     target_emb = np.array(token_emb).mean(axis=0).tolist()\n",
        "\n",
        "#     for k, v in embed.items():\n",
        "#         emb_dist = np.linalg.norm(np.array(target_emb) - np.array(v))\n",
        "#         res[k] = emb_dist\n",
        "\n",
        "#     sorted_dict = sorted(res.items(), key=operator.itemgetter(1))\n",
        "#     return sorted_dict[:top_n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lffN4AILf3XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print (get_similarity(\"ibm limited\"))\n",
        "# print (get_similarity(\"e & y\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyT-wjxErvK1",
        "colab_type": "text"
      },
      "source": [
        "### Two input siamese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WIlYvqko9F7",
        "colab_type": "text"
      },
      "source": [
        "Approach 1 : Using only character embeddings and Approach 2 : Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxNqKCHk_Jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9219ace8-a8ae-4432-947d-5c578a14a52a"
      },
      "source": [
        "def clean(word):\n",
        "    word = word.lower()\n",
        "    word = re.sub(\"[^A-Za-z0-9&]+\", \" \", word)\n",
        "    w_t = \" \".join([i for i in word_tokenize(word) if i not in stopset])\n",
        "    w_t = unidecode(w_t)\n",
        "    return w_t\n",
        "\n",
        "clean_names = []\n",
        "for i in tqdm(range(len(unique_companies))):\n",
        "    clean_names.append(clean(unique_companies[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7004634/7004634 [08:35<00:00, 13593.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWUG61yOYBSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "b668135e-d7c3-4e3b-89c9-b3d3bc26bc26"
      },
      "source": [
        "from collections import OrderedDict\n",
        "from itertools import chain\n",
        "import copy\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "chars = sorted(list(OrderedDict.fromkeys(chain.from_iterable(clean_names))))\n",
        "# remove empty space\n",
        "chars.pop(0)\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['&',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAU2XpQ_Z3pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f29a5496-b4e4-4fd0-ebdc-1c5a2e4fde18"
      },
      "source": [
        "max_word_len = max([len(n) for n in clean_names])\n",
        "max_word_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qytbag1YKvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "9cc4e51d-1d9c-444b-dcfc-141514d13a62"
      },
      "source": [
        "c2id = {c : i for i, c in enumerate(chars)}\n",
        "id2c = {i : c for i, c in enumerate(chars)}\n",
        "c2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'&': 0,\n",
              " '0': 1,\n",
              " '1': 2,\n",
              " '2': 3,\n",
              " '3': 4,\n",
              " '4': 5,\n",
              " '5': 6,\n",
              " '6': 7,\n",
              " '7': 8,\n",
              " '8': 9,\n",
              " '9': 10,\n",
              " 'a': 11,\n",
              " 'b': 12,\n",
              " 'c': 13,\n",
              " 'd': 14,\n",
              " 'e': 15,\n",
              " 'f': 16,\n",
              " 'g': 17,\n",
              " 'h': 18,\n",
              " 'i': 19,\n",
              " 'j': 20,\n",
              " 'k': 21,\n",
              " 'l': 22,\n",
              " 'm': 23,\n",
              " 'n': 24,\n",
              " 'o': 25,\n",
              " 'p': 26,\n",
              " 'q': 27,\n",
              " 'r': 28,\n",
              " 's': 29,\n",
              " 't': 30,\n",
              " 'u': 31,\n",
              " 'v': 32,\n",
              " 'w': 33,\n",
              " 'x': 34,\n",
              " 'y': 35,\n",
              " 'z': 36}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xILmT7U6V6GX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c12bdfc1-07c8-4ff7-b49a-471515b1fdf0"
      },
      "source": [
        "# import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Embedding, LSTM, Dropout, Dense, Flatten, Bidirectional, BatchNormalization\n",
        "from keras.layers import Subtract, Multiply, Lambda, Concatenate, Input, GRU, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QhMe5yHdMH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create alias for given company names using different rules\n",
        "# we need different ways one company name can be represented\n",
        "\n",
        "def custom_rules(name):\n",
        "    na = copy.deepcopy(name)\n",
        "    if ((\" & \" in name) | (\" and \" in name) and (name.count(\" & \") == 1 | name.count(\" and \") == 1)):\n",
        "        company_dict[na].append(name.replace(\" & \", \" and \"))\n",
        "        if (\" and \" in name):\n",
        "            name = name.replace(\" and \", \" & \")\n",
        "            company_dict[na].append(name)\n",
        "        if (len(name.split(\" & \")) == 1):\n",
        "            name = name.replace(\"&\", \" & \")\n",
        "        if (len(name.split(\" & \")[0]) > 1):\n",
        "            pre = \"\"\n",
        "            try:\n",
        "                for i in name.split(\" & \")[0].split(\" \"):\n",
        "                    if (len(i)!=0):\n",
        "                        pre += i[0]\n",
        "                        pre += \" \"\n",
        "            except IndexError:\n",
        "                pre = name.split(\" & \")[0][0]\n",
        "            company_dict[na].append(pre + \"and \" + name.split(\"& \")[1])\n",
        "            company_dict[na].append(pre + \"& \" + name.split(\"&\")[1])\n",
        "        elif (len(name.split(\"&\")[1]) > 1):\n",
        "            company_dict[na].append(name.split(\" & \")[0] + \" and \" + name.split(\" & \")[1].split(\" \")[0] + \" \" + (\" \").join(name.split(\" & \")[1].split(\" \")[1:]))\n",
        "            company_dict[na].append(name.split(\" & \")[0] + \" & \" + name.split(\" & \")[1].split(\" \")[0] + \" \" + (\" \").join(name.split(\" & \")[1].split(\" \")[1:]))\n",
        "        elif (len(name.split(\" & \")[0]) > 1 and len(name.split(\" & \")[1]) > 1):\n",
        "            pre = \"\"\n",
        "            try:\n",
        "                for i in name.split(\" & \")[0].split(\" \"):\n",
        "                    if (len(i)!=0):\n",
        "                        pre += i[0]\n",
        "                        pre += \" \"\n",
        "            except IndexError:\n",
        "                pre = name.split(\" & \")[0][0]\n",
        "            company_dict[na].append(pre + \"and \" + name.split(\" & \")[1].split(\" \")[0] + \" \" + (\" \").join(name.split(\" & \")[1].split(\" \")[1:]))\n",
        "            company_dict[na].append(pre + \"& \" + name.split(\" & \")[1].split(\" \")[0] + \" \" + (\" \").join(name.split(\" & \")[1].split(\" \")[1:]))\n",
        "    if (\"inc\" in name or \"incorporated\" in name):\n",
        "        company_dict[na].append(name.replace(\"inc\", \"incorporation\"))\n",
        "    if (\"pvt\" in name):\n",
        "        company_dict[na].append(name.replace(\"pvt\", \"private\"))\n",
        "    if (\"private\" in name):\n",
        "        company_dict[na].append(name.replace(\"private\", \"pvt\"))\n",
        "    if (\"company\" in name):\n",
        "        company_dict[na].append(name.replace(\"company\", \"co\"))\n",
        "    if (\"ltd\" in name):\n",
        "        company_dict[na].append(name.replace(\"ltd\", \"limited\"))\n",
        "    if (\"limited\" in name):\n",
        "        company_dict[na].append(name.replace(\"limited\", \"ltd\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3F31IoqUJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "company_dict = defaultdict(list)\n",
        "for c in clean_names:\n",
        "    company_dict[c].append(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE3pg6wwga3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e31599a-cdf1-4677-bfb2-2159395601cd"
      },
      "source": [
        "for c in tqdm(company_dict.keys()):\n",
        "    custom_rules(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6968165/6968165 [00:12<00:00, 562412.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzZ3QoK-oY63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ebd074e5-32fe-4115-9fa7-70b96fa59d69"
      },
      "source": [
        "print (\"Previous Length:\", len(list(company_dict.keys())))\n",
        "new_dict = defaultdict(list)\n",
        "for k, v in company_dict.items():\n",
        "    if len(list(set(v))) >= 2 and not k.startswith(\"&\") and not k.startswith(\"and\") and not k[0].isdigit() and len(k) >= 10:\n",
        "        new_dict[k] = v\n",
        "print (\"New Length:\", len(list(new_dict.keys())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previous Length: 6968165\n",
            "New Length: 1467895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4gAqFlXRkLS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "#### Approach 1 : Using character Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTwYc1PKTZBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split = int(0.8 * len(new_dict.keys()))\n",
        "train, val = dict(list(new_dict.items())[:split]), dict(list(new_dict.items())[split:])\n",
        "print (\"Training:\", len(list(train.keys())))\n",
        "print (\"Validation:\", len(list(val.keys())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PS-8rEIZLkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = dict(sorted(train.items()))\n",
        "val = dict(sorted(val.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b27KBVLk_OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, name_dict, c2id):\n",
        "        self.name = name_dict\n",
        "        self.c2id = c2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.name.keys())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X1 = []\n",
        "        chosen = list(self.name.values())[idx]\n",
        "        cname = random.choice(chosen).split(\" \")\n",
        "        cname = list(filter(None, cname))\n",
        "        for word in cname:\n",
        "            for char in word:\n",
        "                X1.append(self.c2id[char])\n",
        "        X1.extend([len(self.c2id)+1 for i in range(max_word_len-len(X1))])\n",
        "        X2, Y = self._draw(cname, chosen, idx)\n",
        "        return np.array(X1), np.array(X2), np.array(int(Y))\n",
        "    \n",
        "    def _draw(self, orig_word, chosen, chosen_idx):\n",
        "        same = random.random() < 0.5\n",
        "        # if not same, get the words having same first letter\n",
        "        # print (same, orig_word, chosen_idx, chosen)\n",
        "        if not same:\n",
        "            x2 = []\n",
        "            # candidates = [idx for idx, k in enumerate(self.name.keys()) if k[0] == orig_word[0][0]]\n",
        "            candidates = []\n",
        "            candidates = [idx for idx, k in enumerate(list(self.name.keys())[chosen_idx+1:chosen_idx+11]) if k[0] == orig_word[0][0]]\n",
        "            candidates.extend([idx for idx, k in enumerate(list(self.name.keys())[chosen_idx-11:chosen_idx-1]) if k[0] == orig_word[0][0]])\n",
        "            # print (candidates, orig_word, chosen_idx)\n",
        "            cname = random.choice(list(self.name.values())[random.choice(candidates)]).split(\" \")\n",
        "            # print (cname)\n",
        "            for word in cname:\n",
        "                for char in word:\n",
        "                    x2.append(self.c2id[char])\n",
        "            x2.extend([len(self.c2id)+1 for i in range(max_word_len-len(x2))])\n",
        "        # choose a different word other than the chosen original word\n",
        "        else:\n",
        "            x2 = []\n",
        "            while (1):\n",
        "                cname = random.choice(chosen).split(\" \")\n",
        "                if orig_word != cname:\n",
        "                    break\n",
        "            for word in cname:\n",
        "                for char in word:\n",
        "                    x2.append(self.c2id[char])\n",
        "            x2.extend([len(self.c2id)+1 for i in range(max_word_len-len(x2))])\n",
        "        return x2, same\n",
        "\n",
        "# class Dataloader(keras.utils.Sequence):\n",
        "#     def __init__(self, dataset, batch_size: int = 256):\n",
        "#         self.dataset = dataset\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.dataset) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, i):\n",
        "#         start = i * self.batch_size\n",
        "#         stop = (i + 1) * self.batch_size\n",
        "#         data = []\n",
        "#         for j in range(start, stop):\n",
        "#             d = self.dataset[j]\n",
        "#             data.append([[d[0], d[1]], d[2]])\n",
        "\n",
        "#         # transpose list of lists\n",
        "#         batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "#         return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBIDeadbRnpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = Dataset(train, c2id)\n",
        "val_dataset = Dataset(val, c2id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFo6Z6PSRnxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdedf4bb-d3d4-4e5b-c704-e3bb65a16325"
      },
      "source": [
        "x, y, z = val_dataset[0]\n",
        "c1 = \"\"\n",
        "for n in x:\n",
        "    if n != 38:\n",
        "        c1 += id2c[n]\n",
        "    else:\n",
        "        break\n",
        "c2 = \"\"\n",
        "for n in y:\n",
        "    if n != 38:\n",
        "        c2 += id2c[n]\n",
        "    else:\n",
        "        break\n",
        "print (c1, c2, z, x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a&aadviesgroep aandabuildingservices 1 (108,) (108,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJwarZascSu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c8a02663-d50f-44cd-9c4e-a3f6474df963"
      },
      "source": [
        "# # train_dataloader = Dataloader(train_dataset)\n",
        "# # val_dataloader = Dataloader(val_dataset)\n",
        "# # len(train_dataloader),len(train_dataset),\n",
        "\n",
        "# %%time\n",
        "\n",
        "# train_x1 = []\n",
        "# train_x2 = []\n",
        "# train_y = []\n",
        "# for i in range(100000):\n",
        "#     data = train_dataset[i]\n",
        "#     train_x1.append(data[0])\n",
        "#     train_x2.append(data[1])\n",
        "#     train_y.append(data[2])\n",
        "\n",
        "# val_x1 = []\n",
        "# val_x2 = []\n",
        "# val_y = []\n",
        "# for i in range(5000):\n",
        "#     data = val_dataset[i]\n",
        "#     val_x1.append(data[0])\n",
        "#     val_x2.append(data[1])\n",
        "#     val_y.append(data[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 17s, sys: 5.34 ms, total: 3min 17s\n",
            "Wall time: 3min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00EBKkLL6ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.savez('train.npz', name1=np.array(train_x1), name2=np.array(train_x2), name3=np.array(train_y))\n",
        "# np.savez('val.npz', name1=np.array(val_x1), name2=np.array(val_x2), name3=np.array(val_y))\n",
        "\n",
        "# %time !cp \"/content/train.npz\" \"/content/drive/My Drive/Colab Notebooks/train.npz\"\n",
        "# %time !cp \"/content/val.npz\" \"/content/drive/My Drive/Colab Notebooks/val.npz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4aM48nDqN7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load(\"train.npz\")\n",
        "train_x1, train_x2, train_y = data[\"name1\"], data[\"name2\"], data[\"name3\"] \n",
        "data = np.load(\"val.npz\")\n",
        "val_x1, val_x2, val_y = data[\"name1\"], data[\"name2\"], data[\"name3\"] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJjpV239zB2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_x1, train_x2, train_y = np.array(train_x1), np.array(train_x2), np.array(train_y)\n",
        "# val_x1, val_x2, val_y = np.array(val_x1), np.array(val_x2), np.array(val_y)\n",
        "\n",
        "idx = np.arange(train_x1.shape[0])\n",
        "random.shuffle(idx)\n",
        "train_x1, train_x2, train_y = train_x1[idx, :], train_x2[idx, :], train_y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCSuamjcS2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "fc7caf7b-45d9-4d00-f38f-30ac945d2f5e"
      },
      "source": [
        "def cosine_distance(vects):\n",
        "    x, y = vects\n",
        "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "\n",
        "def cos_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "thresh = 0.5\n",
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < thresh, y_true.dtype)))\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return 0.5 * K.mean(y_true * square_pred + (1-y_true) * margin_square)\n",
        "\n",
        "def siamese_network():\n",
        "    inp = Input(shape=(max_word_len,))\n",
        "    x = Embedding(input_dim=len(c2id.keys())+1,\n",
        "                  output_dim=128,\n",
        "                  input_length=max_word_len)(inp)\n",
        "    x = GRU(128, return_sequences=True)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(x)\n",
        "    return Model(inputs=inp, outputs=norm_layer)\n",
        "\n",
        "siamese_model = siamese_network()\n",
        "siamese_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_80\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_117 (InputLayer)       (None, 108)               0         \n",
            "_________________________________________________________________\n",
            "embedding_43 (Embedding)     (None, 108, 128)          4864      \n",
            "_________________________________________________________________\n",
            "gru_45 (GRU)                 (None, 108, 128)          98688     \n",
            "_________________________________________________________________\n",
            "flatten_40 (Flatten)         (None, 13824)             0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 64)                884800    \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "norm_layer (Lambda)          (None, 32)                0         \n",
            "=================================================================\n",
            "Total params: 990,432\n",
            "Trainable params: 990,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ybw61PL4U2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "bc8a4134-a15c-4a61-89f1-c9522c788738"
      },
      "source": [
        "i1_inp = Input(shape=(max_word_len,))\n",
        "i2_inp = Input(shape=(max_word_len,))\n",
        "\n",
        "i1_embed = siamese_model(i1_inp)\n",
        "i2_embed = siamese_model(i2_inp)\n",
        "\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([i1_embed, i2_embed])\n",
        "\n",
        "model = Model(inputs=[i1_inp, i2_inp], outputs=distance)\n",
        "model.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])\n",
        "print (model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_81\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_118 (InputLayer)          (None, 108)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_119 (InputLayer)          (None, 108)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_80 (Model)                (None, 32)           990432      input_118[0][0]                  \n",
            "                                                                 input_119[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_39 (Lambda)              (None, 1)            0           model_80[1][0]                   \n",
            "                                                                 model_80[2][0]                   \n",
            "==================================================================================================\n",
            "Total params: 990,432\n",
            "Trainable params: 990,432\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-lCA9Ldhn_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True, verbose=1)]\n",
        "history = model.fit(x=[train_x1, train_x2], y=train_y, \n",
        "                    batch_size=1024, \n",
        "                    epochs=5,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=[[val_x1, val_x2], val_y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMq3lgra1FzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efdedced-0ef3-4c04-ad6e-1597de922f26"
      },
      "source": [
        "def compute_accuracy(predictions, labels):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return np.mean(labels==(predictions.ravel() < thresh))\n",
        "\n",
        "preds = model.predict(x=[val_x1, val_x2])\n",
        "print (compute_accuracy(preds, val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iL20tniokjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "203d4dad-1467-449d-aada-7f635a6add87"
      },
      "source": [
        "for i in range(50):\n",
        "    c1 = \"\"\n",
        "    for n in val_x1[i]:\n",
        "        if n != 38:\n",
        "            c1 += id2c[n]\n",
        "    c2 = \"\"\n",
        "    for n in val_x2[i]:\n",
        "        if n != 38:\n",
        "            c2 += id2c[n]\n",
        "    print (c1, c2, preds[i], \"G:\", val_y[i], \"P:\", int(preds[i] < thresh))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a&aadviesgroep aandadisposal [1.052872] G: 0 P: 0\n",
            "a&aaerospaceinc aandaaerospaceinc [0.35893422] G: 1 P: 1\n",
            "a&aarchitectssdnbhd a&aadviesgroep [0.8297443] G: 0 P: 0\n",
            "aandabeautysalonltd aandaarchitectssdnbhd [0.26824713] G: 0 P: 1\n",
            "a&abuildingservices aandabuildingservices [0.95419043] G: 1 P: 0\n",
            "aandaconstructioncompany a&abeautysalonlimited [0.00031623] G: 0 P: 1\n",
            "a&acourtreportingandvideoconferencing a&acourtreporting [0.0337266] G: 1 P: 1\n",
            "a&adentallabltd aandabuildingservices [0.95419043] G: 0 P: 0\n",
            "a&adisposal aandadisposal [0.4216389] G: 1 P: 1\n",
            "aandadrywallllc aandadrywallllc [0.00031623] G: 0 P: 1\n",
            "a&aelectronicsassemblyinc aandaelectronicsassemblyinc [0.00031623] G: 1 P: 1\n",
            "a&aengcoltdacehumanism&acebusiness aandaengcoltdacehumanism [0.00031623] G: 1 P: 1\n",
            "a&aenterprisesparentcompanyofblueprintacademy&innovativeonlinesolutions aandabeautysalonltd [0.00031623] G: 0 P: 1\n",
            "a&aevents&marketing a&adrywallllc [0.00031623] G: 0 P: 1\n",
            "aandafacilityservicesinc aandabuildingservices [0.63422334] G: 0 P: 0\n",
            "a&agroupconsulting aandagroupconsulting [0.00031623] G: 1 P: 1\n",
            "aandahealthcarelimited a&ahealthcarelimited [0.00031623] G: 1 P: 1\n",
            "a&aholdingllc aandaholdingllc [0.00031623] G: 1 P: 1\n",
            "aandaimportingllc a&aimportingllc [0.44797078] G: 1 P: 1\n",
            "aandaindustriesbv aandaadviesgroep [0.9569873] G: 0 P: 0\n",
            "aandainternationalgroup a&ainternationalgroup [0.00031623] G: 1 P: 1\n",
            "a&ainternationalincorporation a&aarchitectssdnbhd [0.8301356] G: 0 P: 0\n",
            "a&alanguageservicesincorporation aandaconstructioncompany [0.3467812] G: 0 P: 1\n",
            "a&alivesound aandaadviesgroep [1.0251977] G: 0 P: 0\n",
            "a&amarineservice a&adisposal [0.03296432] G: 0 P: 1\n",
            "a&amechanicalinc aandamechanicalinc [0.00031623] G: 1 P: 1\n",
            "a&apaininstituteofstlouis aandacourtreportingandvideoconferencing [0.68779856] G: 0 P: 0\n",
            "a&apaintingcontractorscorp aandapaintingcontractorscorp [0.41658297] G: 1 P: 1\n",
            "a&aproductcompanyllc aandaproductcompanyllc [0.00031623] G: 1 P: 1\n",
            "aandaprojectontwikkelingbv a&adentallablimited [0.70316535] G: 0 P: 0\n",
            "a&apropertydevelopmentserviceslimited aandapropertydevelopmentserviceslimited [0.00031623] G: 1 P: 1\n",
            "a&asupply a&acourtreporting&videoconferencing [0.00031623] G: 0 P: 1\n",
            "a&atermiteandpestcontrol aandatermite [0.00031623] G: 1 P: 1\n",
            "a&atopperssouth a&adentallabltd [0.33810082] G: 0 P: 1\n",
            "a&atrucking aandatrucking [0.13047823] G: 1 P: 1\n",
            "a&awesternstoreofalexandriallc aandawesternstoreofalexandriallc [0.21596034] G: 1 P: 1\n",
            "a&baccounting aandaconstructioncompany [0.9900957] G: 0 P: 0\n",
            "aandbactivdistribution aandaadviesgroep [1.3156271] G: 0 P: 0\n",
            "a&bassociateslimited aandabuildingservices [0.95419043] G: 0 P: 0\n",
            "aandbbrands4all a&bbrands4all [0.00031623] G: 1 P: 1\n",
            "a&bcontractingllc a&aaerospaceinc [0.69299483] G: 0 P: 0\n",
            "a&bdentalpc aandbdentalpc [0.00031623] G: 1 P: 1\n",
            "aandbdesignfengshuiconsulting a&bdesignfengshuiconsulting [0.00031623] G: 1 P: 1\n",
            "aandbelectricalcontractorslimited aandadisposal [0.43779325] G: 0 P: 1\n",
            "a&bengineeringconsultantspa aandbengineeringconsultantspa [0.00031623] G: 1 P: 1\n",
            "a&bfreightlineincorporation a&bfreightlineinc [0.00031623] G: 1 P: 1\n",
            "a&bgourmetfoodcorp a&aarchitectssdnbhd [0.8301356] G: 0 P: 0\n",
            "a&bgroupincorporation a&adisposal [0.03296432] G: 0 P: 1\n",
            "a&bhomehealthcareservicesinc a&bhomehealthcareservicesincorporation [0.00031623] G: 1 P: 1\n",
            "a&bhvacservicesincorporation a&bhvacservicesinc [0.00031623] G: 1 P: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT2zbOT1Vrqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"siamese_company.h5\")\n",
        "%time !cp \"/content/siamese_company.h5\" \"/content/drive/My Drive/Colab Notebooks/siamese_company.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEtThJaRoMy",
        "colab_type": "text"
      },
      "source": [
        "#### Approach 2 : Using BERT embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9woqvpt51qT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "e1c95f4e-e9ef-42be-884a-4f3c66b67a4d"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 29.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.5MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=8b6598e76a1ee7d42a8790735c1a2592276b798da709e341e06453fc7cc6f79a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=12d3ea3c3973d115fe17e838367348feb10815e726c7e982069e180917d9b566\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=f10f9ae9a6c27d4e4d20b0da29b16ed51c8cad88b0d7cfc92691ede9357cd975\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kdW-drYOQ-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93a03f75-4669-4b55-ff4f-0386df8ff3e8"
      },
      "source": [
        "split = int(0.8 * len(new_dict.keys()))\n",
        "train, val = dict(list(new_dict.items())[:split]), dict(list(new_dict.items())[split:])\n",
        "print (\"Training:\", len(list(train.keys())))\n",
        "print (\"Validation:\", len(list(val.keys())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: 1174316\n",
            "Validation: 293579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h8_DrLZWvSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = dict(sorted(train.items()))\n",
        "val = dict(sorted(val.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APzxJlAqLaR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Embedding, LSTM, Dropout, Dense, Flatten, Bidirectional, BatchNormalization\n",
        "from keras.layers import Subtract, Multiply, Lambda, Concatenate, Input, GRU, GlobalMaxPool1D, Conv1D\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "import bert\n",
        "import tensorflow_hub as hub\n",
        "from bert import bert_tokenization\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "max_word_len = 108\n",
        "BertTokenizer = bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7cXOMquWxOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, name_dict):\n",
        "        self.name = name_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.name.keys())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chosen = list(self.name.values())[idx]\n",
        "        cname = random.choice(chosen)\n",
        "        token = tokenizer.tokenize(cname)\n",
        "        X1 = tokenizer.convert_tokens_to_ids(token)\n",
        "        X1.extend([0 for i in range(max_word_len-len(X1))])\n",
        "        # print (cname, token, X1)\n",
        "        X2, Y = self._draw(cname, chosen, idx)\n",
        "        return np.array(X1), np.array(X2), np.array(int(Y))\n",
        "    \n",
        "    def _draw(self, orig_word, chosen, chosen_idx):\n",
        "        same = random.random() < 0.5\n",
        "        # if not same, get the words having same first letter\n",
        "        # print (same, orig_word, chosen_idx, chosen)\n",
        "        if not same:\n",
        "            x2 = []\n",
        "            # candidates = [idx for idx, k in enumerate(self.name.keys()) if k[0] == orig_word[0][0]]\n",
        "            candidates = []\n",
        "            candidates = [idx for idx, k in enumerate(list(self.name.keys())[chosen_idx+1:chosen_idx+11]) if k[0] == orig_word[0][0]]\n",
        "            candidates.extend([idx for idx, k in enumerate(list(self.name.keys())[chosen_idx-11:chosen_idx-1]) if k[0] == orig_word[0][0]])\n",
        "            # print (candidates, orig_word, chosen_idx)\n",
        "            cname = random.choice(list(self.name.values())[random.choice(candidates)])\n",
        "            token = tokenizer.tokenize(cname)\n",
        "            x2 = tokenizer.convert_tokens_to_ids(token)\n",
        "            x2.extend([0 for i in range(max_word_len-len(x2))])\n",
        "            # print (cname, token, x2)\n",
        "        # choose a different word other than the chosen original word\n",
        "        else:\n",
        "            x2 = []\n",
        "            while (1):\n",
        "                cname = random.choice(chosen)\n",
        "                if orig_word != cname:\n",
        "                    break\n",
        "            token = tokenizer.tokenize(cname)\n",
        "            x2 = tokenizer.convert_tokens_to_ids(token)\n",
        "            x2.extend([0 for i in range(max_word_len-len(x2))])\n",
        "            # print (cname, token, x2)\n",
        "        return x2, same\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ucnHhKW7X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = Dataset(train)\n",
        "val_dataset = Dataset(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmupgh2ZYaA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "90d1ef94-194c-4e5e-d7b6-58083ebbf43f"
      },
      "source": [
        "x, y, z = train_dataset[0]\n",
        "print (x, y, z)\n",
        "c1 = tokenizer.convert_ids_to_tokens(x)\n",
        "c2 = tokenizer.convert_ids_to_tokens(y)\n",
        "print (c1, c2, z, x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1037  1004  1037  3229 10050  4371 26189  2102  3132     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0] [ 1037  1998  1037  3229 10050  4371 26189  2102  5183     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0] 1\n",
            "['a', '&', 'a', 'access', '##ori', '##ze', 'pv', '##t', 'limited', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] ['a', 'and', 'a', 'access', '##ori', '##ze', 'pv', '##t', 'ltd', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] 1 (108,) (108,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifhUbM_GW2qJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "117b8946-2864-4947-d00c-8f4246de23bc"
      },
      "source": [
        "%%time\n",
        "\n",
        "train_x1 = []\n",
        "train_x2 = []\n",
        "train_y = []\n",
        "for i in range(100000):\n",
        "    data = train_dataset[i]\n",
        "    train_x1.append(data[0])\n",
        "    train_x2.append(data[1])\n",
        "    train_y.append(data[2])\n",
        "\n",
        "val_x1 = []\n",
        "val_x2 = []\n",
        "val_y = []\n",
        "for i in range(5000):\n",
        "    data = val_dataset[i]\n",
        "    val_x1.append(data[0])\n",
        "    val_x2.append(data[1])\n",
        "    val_y.append(data[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5h 36min 34s, sys: 28.8 s, total: 5h 37min 3s\n",
            "Wall time: 5h 37min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNgE--M-cRrt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "08eccf13-ce49-42ec-9d12-f622dec4751a"
      },
      "source": [
        "np.savez('train_bert.npz', name1=np.array(train_x1), name2=np.array(train_x2), name3=np.array(train_y))\n",
        "np.savez('val_bert.npz', name1=np.array(val_x1), name2=np.array(val_x2), name3=np.array(val_y))\n",
        "\n",
        "%time !cp \"/content/train_bert.npz\" \"/content/drive/My Drive/Colab Notebooks/train_bert.npz\"\n",
        "%time !cp \"/content/val_bert.npz\" \"/content/drive/My Drive/Colab Notebooks/val_bert.npz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.5 ms, sys: 56 ms, total: 104 ms\n",
            "Wall time: 15.3 s\n",
            "CPU times: user 44.7 ms, sys: 59 ms, total: 104 ms\n",
            "Wall time: 15.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ku-lrsHhcRsB",
        "colab": {}
      },
      "source": [
        "data = np.load(\"train_bert.npz\")\n",
        "train_x1, train_x2, train_y = data[\"name1\"], data[\"name2\"], data[\"name3\"] \n",
        "data = np.load(\"val_bert.npz\")\n",
        "val_x1, val_x2, val_y = data[\"name1\"], data[\"name2\"], data[\"name3\"] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_8JHHk-ZcRsS",
        "colab": {}
      },
      "source": [
        "train_x1, train_x2, train_y = np.array(train_x1), np.array(train_x2), np.array(train_y)\n",
        "val_x1, val_x2, val_y = np.array(val_x1), np.array(val_x2), np.array(val_y)\n",
        "\n",
        "idx = np.arange(train_x1.shape[0])\n",
        "random.shuffle(idx)\n",
        "train_x1, train_x2, train_y = train_x1[idx, :], train_x2[idx, :], train_y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_ZnLnYtcRsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "a47ff011-aad6-4da1-8562-80255075235b"
      },
      "source": [
        "thresh = 0.5\n",
        "\n",
        "def cosine_distance(vects):\n",
        "    x, y = vects\n",
        "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "\n",
        "def cos_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < thresh, y_true.dtype)))\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return 0.5 * K.mean(y_true * square_pred + (1-y_true) * margin_square)\n",
        "\n",
        "# def siamese_network():\n",
        "#     inp = Input(shape=(max_word_len,))\n",
        "#     x = Embedding(input_dim=len(tokenizer.vocab)+1,\n",
        "#                   output_dim=128,\n",
        "#                   input_length=max_word_len)(inp)\n",
        "#     x = GRU(128, return_sequences=True)(x)\n",
        "#     x = Flatten()(x)\n",
        "#     x = Dense(64, activation='relu')(x)\n",
        "#     x = Dropout(0.4)(x)\n",
        "#     x = Dense(32, activation='relu')(x)\n",
        "#     norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(x)\n",
        "#     return Model(inputs=inp, outputs=norm_layer)\n",
        "\n",
        "def siamese_network():\n",
        "    inp = Input(shape=(max_word_len,))\n",
        "    x = Embedding(input_dim=len(tokenizer.vocab)+1,\n",
        "                  output_dim=200,\n",
        "                  input_length=max_word_len)(inp)\n",
        "    x = Conv1D(filters=100,\n",
        "               kernel_size=3,\n",
        "               padding=\"valid\",\n",
        "               activation=\"relu\")(x)\n",
        "    x = Conv1D(filters=100,\n",
        "               kernel_size=4,\n",
        "               padding=\"valid\",\n",
        "               activation=\"relu\")(x)\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(x)\n",
        "    return Model(inputs=inp, outputs=norm_layer)\n",
        "\n",
        "siamese_model = siamese_network()\n",
        "siamese_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        (None, 108)               0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 108, 200)          6104600   \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 106, 100)          60100     \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 103, 100)          40100     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "norm_layer (Lambda)          (None, 32)                0         \n",
            "=================================================================\n",
            "Total params: 6,213,344\n",
            "Trainable params: 6,213,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6Jdj72FcRsq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "00e40c02-92b1-473f-bfa1-6c419d1e5f9f"
      },
      "source": [
        "i1_inp = Input(shape=(max_word_len,))\n",
        "i2_inp = Input(shape=(max_word_len,))\n",
        "\n",
        "i1_embed = siamese_model(i1_inp)\n",
        "i2_embed = siamese_model(i2_inp)\n",
        "\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([i1_embed, i2_embed])\n",
        "\n",
        "model = Model(inputs=[i1_inp, i2_inp], outputs=distance)\n",
        "model.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])\n",
        "print (model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_19\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           (None, 108)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_30 (InputLayer)           (None, 108)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_18 (Model)                (None, 32)           6213344     input_29[0][0]                   \n",
            "                                                                 input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 1)            0           model_18[1][0]                   \n",
            "                                                                 model_18[2][0]                   \n",
            "==================================================================================================\n",
            "Total params: 6,213,344\n",
            "Trainable params: 6,213,344\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "59RilI5McRs1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "cdc1e955-1ebc-4426-c41d-2dd800888caa"
      },
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True, verbose=1)]\n",
        "history = model.fit(x=[train_x1, train_x2], y=train_y, \n",
        "                    batch_size=1024, \n",
        "                    epochs=5,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=[[val_x1, val_x2], val_y])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "100000/100000 [==============================] - 9s 93us/step - loss: 0.0208 - accuracy: 0.9469 - val_loss: 0.1000 - val_accuracy: 0.6826\n",
            "Epoch 2/5\n",
            "100000/100000 [==============================] - 8s 80us/step - loss: 6.0697e-05 - accuracy: 0.9999 - val_loss: 0.1887 - val_accuracy: 0.5637\n",
            "Epoch 3/5\n",
            "100000/100000 [==============================] - 8s 80us/step - loss: 3.7642e-05 - accuracy: 0.9999 - val_loss: 0.1755 - val_accuracy: 0.5637\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7YNK0xMcRs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec6345ab-c7a4-4e04-b8d2-f310ed1c48fd"
      },
      "source": [
        "def compute_accuracy(predictions, labels):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return np.mean(labels==(predictions.ravel() < thresh))\n",
        "\n",
        "preds = model.predict(x=[val_x1, val_x2])\n",
        "print (compute_accuracy(preds, val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2cA95seJD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "391188d3-6cbe-4f49-b18a-9c1b8491f2ef"
      },
      "source": [
        "model.save(\"siamese_company_bert.h5\")\n",
        "%time !cp \"/content/siamese_company_bert.h5\" \"/content/drive/My Drive/Colab Notebooks/siamese_company_bert.h5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.76 ms, sys: 65.1 ms, total: 74.9 ms\n",
            "Wall time: 2.24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKo_09E-mYPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62a5cb4a-9151-411d-cb52-9a5f5d54e327"
      },
      "source": [
        "print (np.unique(val_y, return_counts=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([2452, 2548]))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}